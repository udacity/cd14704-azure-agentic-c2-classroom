{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c697a75",
   "metadata": {},
   "source": [
    "# Multi-Agent Restaurant Menu Analytics System\n",
    " \n",
    "## Overview\n",
    " This notebook demonstrates **parallel agent processing** with data validation. Multiple specialized agents analyze different aspects of restaurant menu data simultaneously, their outputs are cleaned and standardized, then validated for quality assurance.\n",
    "\n",
    " <div align=\"center\">\n",
    "<img src=\"lesson_4.png\" alt=\"Alt text\" width=\"650\"/>\n",
    "</div>\n",
    " \n",
    " ### Key Concepts Covered:\n",
    " 1. **Parallel Agent Execution**: Multiple agents process data simultaneously using `asyncio.gather()`\n",
    " 2. **Data Loading Agent**: Specialized agent for file I/O operations\n",
    " 3. **Domain-Specific Analyzers**: Agents with narrow analytical focus\n",
    " 4. **Output Standardization**: Cleaning agent formats raw outputs into consistent structure\n",
    " 5. **Quality Validation**: Checker agent validates completeness and accuracy\n",
    " 6. **Pipeline Architecture**: Data flows through distinct processing stages\n",
    "\n",
    " ## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b947019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a74d8b",
   "metadata": {},
   "source": [
    " ## 2. Define Agent Instructions\n",
    " \n",
    " Each agent has precise instructions defining its role, behavior, and output format.\n",
    " This ensures consistent, predictable agent behavior.\n",
    "\n",
    " ### 2.1 CSV Loader Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754f7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Loader_Name = \"CSVLoader\"\n",
    "CSV_Loader_Instructions = \"\"\"\n",
    "    You are a CSV Loader Agent.\n",
    "    Your role is to read menu data from a CSV file, extract its contents, and return it as a clean, comma-separated string.\n",
    "    You do not perform analysis — only data loading and formatting.\n",
    "    Keep the output concise and ready for downstream analysis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2ebab",
   "metadata": {},
   "source": [
    " ### 2.2 Main Dish Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76178beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Dish_Analyzer_Name = \"MainDishAnalyzer\"\n",
    "Main_Dish_Analyzer_Instructions = \"\"\"\n",
    "    AI Agent Persona: Main Dish Analytics Assistant\n",
    "    Role: A specialized assistant focused exclusively on analyzing main dish menu items and calculating descriptive statistics.\n",
    "    Behavior: The agent does not answer questions outside the scope of main dish analysis.\n",
    "    Response Style: Always provide calculated results clearly and concisely.\n",
    "    \n",
    "    Agent Instructions:\n",
    "    From the restaurant menu dataset provided, extract the MAIN DISHES and analyze these items only.\n",
    "    Main dishes include: pasta, steak, chicken, fish, burgers, pizza, risotto, lamb, pork, seafood entrees.\n",
    "    \n",
    "    Calculate descriptive statistics including:\n",
    "    - Mean, median, standard deviation, minimum, and maximum for price\n",
    "    - Mean, median, standard deviation for calories (if available)\n",
    "    - Count of items in this category\n",
    "    \n",
    "    Ensure all calculations are based on cleaned data (after removing any anomalies or outliers).\n",
    "    Present the results in a clear, structured format for immediate interpretation.\n",
    "    \n",
    "    Descriptive statistics MUST be presented in JSON format, with two tables:\n",
    "    1. Price Statistics Table\n",
    "    2. Nutritional Statistics Table (calories, etc.)\n",
    "    Add clear titles to the JSON tables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7f8dc",
   "metadata": {},
   "source": [
    " ### 2.3 Beverage Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ccb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beverage_Analyzer_Name = \"BeverageAnalyzer\"\n",
    "Beverage_Analyzer_Instructions = \"\"\"\n",
    "    AI Agent Persona: Beverage Analytics Assistant\n",
    "    Role: A specialized assistant focused exclusively on analyzing beverage menu items and calculating descriptive statistics.\n",
    "    Behavior: The agent does not answer questions outside the scope of beverage analysis.\n",
    "    Response Style: Always provide calculated results clearly and concisely.\n",
    "    \n",
    "    Agent Instructions:\n",
    "    From the restaurant menu dataset provided, extract the BEVERAGES and analyze these items only.\n",
    "    Beverages include: coffee, tea, juice, soda, wine, beer, cocktails, smoothies, milkshakes, water.\n",
    "    \n",
    "    Calculate descriptive statistics including:\n",
    "    - Mean, median, standard deviation, minimum, and maximum for price\n",
    "    - Mean, median, standard deviation for calories (if available)\n",
    "    - Count of items in this category\n",
    "    \n",
    "    Ensure all calculations are based on cleaned data (after removing any anomalies or outliers).\n",
    "    Present the results in a clear, structured format for immediate interpretation.\n",
    "    \n",
    "    Descriptive statistics MUST be presented in JSON format, with two tables:\n",
    "    1. Price Statistics Table\n",
    "    2. Nutritional Statistics Table (calories, etc.)\n",
    "    Add clear titles to the JSON tables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d57686",
   "metadata": {},
   "source": [
    " ### 2.4 Output Cleaning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91df610",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_Output_Agent_Name = \"CleanOutputAgent\"\n",
    "Clean_Output_Agent_Instructions = \"\"\"\n",
    "    AI Agent Persona: Output Cleaning Specialist\n",
    "    Role: To process and sanitize the raw outputs from analysis agents.\n",
    "    Behavior: You do not perform new analysis — you only extract and format existing results.\n",
    "    Response Style: Always output in a clean, minimal, structured format.\n",
    "\n",
    "    Cleaning Tasks:\n",
    "    1. From each analyzer's output, extract:\n",
    "       - The list of identified menu items\n",
    "       - The JSON table for price statistics\n",
    "       - The JSON table for nutritional statistics\n",
    "    2. Remove any unrelated text, explanations, commentary, or markdown formatting.\n",
    "    3. Present the cleaned data in the following standardized JSON structure:\n",
    "\n",
    "    {\n",
    "        \"MainDishes\": {\n",
    "            \"IdentifiedItems\": [...],\n",
    "            \"PriceStatistics\": {...},\n",
    "            \"NutritionalStatistics\": {...}\n",
    "        },\n",
    "        \"Beverages\": {\n",
    "            \"IdentifiedItems\": [...],\n",
    "            \"PriceStatistics\": {...},\n",
    "            \"NutritionalStatistics\": {...}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Output ONLY valid JSON. No explanations, no markdown, no additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80154332",
   "metadata": {},
   "source": [
    " ### 2.5 Analysis Validation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07f34598",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis_Checker_Name = \"AnalysisChecker\"\n",
    "Analysis_Checker_Instructions = \"\"\"\n",
    "    AI Agent Persona: Data Analysis Validation Auditor\n",
    "    Role: A specialized agent responsible for verifying that analytics tasks are completed correctly by other agents.\n",
    "    Behavior: The agent does not perform analysis itself but evaluates the completeness and accuracy of other agents' outputs.\n",
    "    Response Style: Always provide a clear, structured validation report or approval.\n",
    "\n",
    "    Validation Tasks:\n",
    "    1. Verify Main Dish Analysis:\n",
    "         Main dish items are identified\n",
    "         Two JSON tables are present: one for price statistics and one for nutritional statistics\n",
    "         All required statistics are present (mean, median, std, min, max)\n",
    "        \n",
    "    2. Verify Beverage Analysis:\n",
    "         Beverage items are identified\n",
    "         Two JSON tables are present: one for price statistics and one for nutritional statistics\n",
    "         All required statistics are present (mean, median, std, min, max)\n",
    "\n",
    "    Decision Logic:\n",
    "    - If BOTH analyses meet ALL criteria → output: \"APPROVED: All analyses complete and valid.\"\n",
    "    - If EITHER analysis fails ANY check → output a detailed error message specifying:\n",
    "      * Which category failed (Main Dishes or Beverages)\n",
    "      * Which specific requirement was not met\n",
    "      * What needs to be corrected\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505cc9d1",
   "metadata": {},
   "source": [
    " ## 3. Load Environment and Initialize Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d49982",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "url = os.getenv(\"URL\")\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "# Create kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Configure Azure OpenAI service\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=\"none\", \n",
    "    api_key=api_key,\n",
    "    base_url=url,\n",
    "    api_version=api_version\n",
    ")\n",
    "\n",
    "# Register service with kernel\n",
    "kernel.add_service(chat_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb6bab2",
   "metadata": {},
   "source": [
    " ## 4. Instantiate All Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19787e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_csv_loader = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=CSV_Loader_Name,\n",
    "    instructions=CSV_Loader_Instructions,\n",
    ")\n",
    "\n",
    "agent_main_dish_analyzer = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Main_Dish_Analyzer_Name,\n",
    "    instructions=Main_Dish_Analyzer_Instructions,\n",
    ")\n",
    "\n",
    "agent_beverage_analyzer = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Beverage_Analyzer_Name,\n",
    "    instructions=Beverage_Analyzer_Instructions,\n",
    ")\n",
    "\n",
    "agent_clean_output = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Clean_Output_Agent_Name,\n",
    "    instructions=Clean_Output_Agent_Instructions,\n",
    ")\n",
    "\n",
    "agent_checker = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Analysis_Checker_Name,\n",
    "    instructions=Analysis_Checker_Instructions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172108fc",
   "metadata": {},
   "source": [
    " ## 5. Helper Functions\n",
    "\n",
    "  ### 5.1 Agent Execution Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b363fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agent(agent, task_input):\n",
    "    \"\"\"\n",
    "    Executes an agent and collects all output messages.\n",
    "    \n",
    "    Args:\n",
    "        agent: The ChatCompletionAgent to invoke\n",
    "        task_input: The input prompt/data for the agent\n",
    "    \n",
    "    Returns:\n",
    "        List of message objects from the agent\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    async for message in agent.invoke(task_input):\n",
    "        outputs.append(message)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0912d1c",
   "metadata": {},
   "source": [
    " ### 5.2 CSV Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a74544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads a CSV file and converts it to a flat comma-separated string.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "        String representation of CSV data\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Flatten the dataframe and join as comma-separated string\n",
    "    flat_data = \", \".join(map(str, df.values.flatten()))\n",
    "    return flat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf4e41",
   "metadata": {},
   "source": [
    " ## 6. Parallel Analysis Function\n",
    " \n",
    " This is the **key**: using `asyncio.gather()` to run multiple agents simultaneously.\n",
    " This dramatically reduces total processing time compared to sequential execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d71262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parallel_analysis(task_input: str):\n",
    "    \"\"\"\n",
    "    Runs multiple analyzer agents in parallel using asyncio.gather().\n",
    "    \n",
    "    This approach is much faster than sequential execution:\n",
    "    - Sequential: Time = T1 + T2\n",
    "    - Parallel: Time ≈ max(T1, T2)\n",
    "    \n",
    "    Args:\n",
    "        task_input: The data to be analyzed\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results from both analyzers\n",
    "    \"\"\"\n",
    "    # Execute both agents simultaneously\n",
    "    results = await asyncio.gather(\n",
    "        run_agent(agent_main_dish_analyzer, task_input),\n",
    "        run_agent(agent_beverage_analyzer, task_input)\n",
    "    )\n",
    "    \n",
    "    # Package results into structured dictionary\n",
    "    merged_output = {\n",
    "        \"MainDishAnalyzer\": results[0][0].content,\n",
    "        \"BeverageAnalyzer\": results[1][0].content\n",
    "    }\n",
    "    return merged_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487affa5",
   "metadata": {},
   "source": [
    " ## 7. Main Processing Pipeline\n",
    " \n",
    " This demonstrates the complete **four-stage pipeline**:\n",
    " 1. **Load**: Read data from CSV\n",
    " 2. **Analyze**: Parallel processing by specialized agents\n",
    " 3. **Clean**: Standardize outputs into consistent format\n",
    " 4. **Validate**: Quality check by validation agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e081adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the complete restaurant menu analytics pipeline.\n",
    "    \n",
    "    Pipeline Stages:\n",
    "    Stage 1: Data Loading\n",
    "    Stage 2: Parallel Analysis (Main Dishes + Beverages)\n",
    "    Stage 3: Output Cleaning and Standardization\n",
    "    Stage 4: Validation and Quality Assurance\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"RESTAURANT MENU ANALYTICS SYSTEM\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # ==================== STAGE 1: DATA LOADING ====================\n",
    "    print(\"\\nSTAGE 1: Loading CSV Data\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    csv_path = \"restaurant_menu.csv\"  # Change to your CSV file path\n",
    "    csv_data = load_csv_file(csv_path)\n",
    "    print(f\"CSV data loaded successfully\")\n",
    "    print(f\"Data preview: {csv_data[:200]}...\\n\")\n",
    "    \n",
    "    # ==================== STAGE 2: PARALLEL ANALYSIS ====================\n",
    "    print(\" STAGE 2: Running Parallel Analysis\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"MainDishAnalyzer and BeverageAnalyzer executing simultaneously...\")\n",
    "    \n",
    "    raw_results = await parallel_analysis(f\"Analyze this restaurant menu data: {csv_data}\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "    print(\"\\nRAW ANALYZER OUTPUTS:\")\n",
    "    print(\"-\" * 70)\n",
    "    for analyzer, output in raw_results.items():\n",
    "        print(f\"\\n[{analyzer}]\")\n",
    "        print(output)\n",
    "    \n",
    "    # ==================== STAGE 3: OUTPUT CLEANING ====================\n",
    "    print(\"\\n\\nSTAGE 3: Cleaning and Standardizing Outputs\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    clean_input = f\"Clean the following outputs: {raw_results}\"\n",
    "    clean_result = await run_agent(agent_clean_output, clean_input)\n",
    "    cleaned_output = clean_result[0].content\n",
    "    \n",
    "    print(\"Output cleaned and standardized\")\n",
    "    print(\"\\nCLEANED OUTPUT:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(cleaned_output)\n",
    "    \n",
    "    # ==================== STAGE 4: VALIDATION ====================\n",
    "    print(\"\\n\\nSTAGE 4: Validating Analysis Quality\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    checker_result = await run_agent(\n",
    "        agent_checker, \n",
    "        f\"Check this cleaned output for completeness and accuracy: {cleaned_output}\"\n",
    "    )\n",
    "    \n",
    "    print(\"VALIDATION RESULT:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(checker_result[0].content)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PIPELINE COMPLETE\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ef809",
   "metadata": {},
   "source": [
    " ## 8. Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7bec4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESTAURANT MENU ANALYTICS SYSTEM\n",
      "======================================================================\n",
      "\n",
      "STAGE 1: Loading CSV Data\n",
      "----------------------------------------------------------------------\n",
      "CSV data loaded successfully\n",
      "Data preview: MENU5506, Spaghetti Carbonara, pasta, 17.46, 720, True, MENU2679, Fettuccine Alfredo, pasta, 15.17, 680, True, MENU2424, Penne Arrabbiata, pasta, 15.52, 620, False, MENU1488, Lasagna Bolognese, pasta,...\n",
      "\n",
      " STAGE 2: Running Parallel Analysis\n",
      "----------------------------------------------------------------------\n",
      "MainDishAnalyzer and BeverageAnalyzer executing simultaneously...\n",
      "\n",
      "Analysis complete!\n",
      "\n",
      "RAW ANALYZER OUTPUTS:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[MainDishAnalyzer]\n",
      "{\n",
      "  \"Price Statistics Table\": {\n",
      "    \"Title\": \"Main Dish Price Statistics\",\n",
      "    \"Mean\": 22.26,\n",
      "    \"Median\": 18.70,\n",
      "    \"StandardDeviation\": 8.11,\n",
      "    \"Minimum\": 12.65,\n",
      "    \"Maximum\": 42.40,\n",
      "    \"Count\": 32\n",
      "  },\n",
      "  \"Nutritional Statistics Table\": {\n",
      "    \"Title\": \"Main Dish Nutrition (Calories) Statistics\",\n",
      "    \"Mean\": 673.4,\n",
      "    \"Median\": 680,\n",
      "    \"StandardDeviation\": 140.2\n",
      "  }\n",
      "}\n",
      "\n",
      "**Notes:**\n",
      "- All calculations are based on 32 menu items classified as main dishes (pasta, steak, chicken, fish, burger, pizza, risotto, lamb, pork, and seafood entrees).\n",
      "- Data was cleaned to exclude non-main dish items and ensure no anomalies or outliers affected the statistics.\n",
      "- Calories analysis used only provided calorie information for main dishes.\n",
      "\n",
      "\n",
      "[BeverageAnalyzer]\n",
      "**Extracted Beverages:**\n",
      "Coffee, Tea, Juice, Soda, Wine, Beer, Cocktails, Smoothies, Milkshakes, Water.\n",
      "\n",
      "**Cleaned Data Process:**\n",
      "- Removed outliers and anomalies; all prices and calories for beverages are within expected ranges, so all provided items are included.\n",
      "\n",
      "---\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Price Statistics Table\": {\n",
      "    \"title\": \"Beverage Price Descriptive Statistics\",\n",
      "    \"mean\": 6.659,\n",
      "    \"median\": 5.39,\n",
      "    \"standard_deviation\": 2.727,\n",
      "    \"minimum\": 1.87,\n",
      "    \"maximum\": 13.54,\n",
      "    \"count\": 38\n",
      "  },\n",
      "  \"Nutritional Statistics Table\": {\n",
      "    \"title\": \"Beverage Calorie Descriptive Statistics\",\n",
      "    \"mean\": 138.16,\n",
      "    \"median\": 120,\n",
      "    \"standard_deviation\": 113.81,\n",
      "    \"minimum\": 0,\n",
      "    \"maximum\": 520,\n",
      "    \"count\": 38\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "**Legend:**\n",
      "- Count represents the number of beverage items analyzed.\n",
      "- All statistics are rounded to two decimal places for clarity.\n",
      "\n",
      "\n",
      "STAGE 3: Cleaning and Standardizing Outputs\n",
      "----------------------------------------------------------------------\n",
      "Output cleaned and standardized\n",
      "\n",
      "CLEANED OUTPUT:\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "    \"MainDishes\": {\n",
      "        \"IdentifiedItems\": [\"pasta\", \"steak\", \"chicken\", \"fish\", \"burger\", \"pizza\", \"risotto\", \"lamb\", \"pork\", \"seafood entrees\"],\n",
      "        \"PriceStatistics\": {\n",
      "            \"Mean\": 22.26,\n",
      "            \"Median\": 18.70,\n",
      "            \"StandardDeviation\": 8.11,\n",
      "            \"Minimum\": 12.65,\n",
      "            \"Maximum\": 42.40,\n",
      "            \"Count\": 32\n",
      "        },\n",
      "        \"NutritionalStatistics\": {\n",
      "            \"Mean\": 673.4,\n",
      "            \"Median\": 680,\n",
      "            \"StandardDeviation\": 140.2\n",
      "        }\n",
      "    },\n",
      "    \"Beverages\": {\n",
      "        \"IdentifiedItems\": [\"Coffee\", \"Tea\", \"Juice\", \"Soda\", \"Wine\", \"Beer\", \"Cocktails\", \"Smoothies\", \"Milkshakes\", \"Water\"],\n",
      "        \"PriceStatistics\": {\n",
      "            \"mean\": 6.659,\n",
      "            \"median\": 5.39,\n",
      "            \"standard_deviation\": 2.727,\n",
      "            \"minimum\": 1.87,\n",
      "            \"maximum\": 13.54,\n",
      "            \"count\": 38\n",
      "        },\n",
      "        \"NutritionalStatistics\": {\n",
      "            \"mean\": 138.16,\n",
      "            \"median\": 120,\n",
      "            \"standard_deviation\": 113.81,\n",
      "            \"minimum\": 0,\n",
      "            \"maximum\": 520,\n",
      "            \"count\": 38\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "STAGE 4: Validating Analysis Quality\n",
      "----------------------------------------------------------------------\n",
      "VALIDATION RESULT:\n",
      "----------------------------------------------------------------------\n",
      "**Validation Report**\n",
      "\n",
      "---\n",
      "\n",
      "### Main Dishes\n",
      "\n",
      "| Requirement | Status | Notes |\n",
      "|-------------|--------|--------|\n",
      "| Identified items present  | ✓ | List provided: 10 items. |\n",
      "| Price statistics JSON table present | ✓ | Table present, labeled 'PriceStatistics'. |\n",
      "| Price stats: mean, median, std, min, max present | ✗ | Only mean, median, std, min, max present (all ok), but also includes 'Count'. |\n",
      "| Nutritional statistics JSON table present | ✓ | Table present, labeled 'NutritionalStatistics'. |\n",
      "| Nutritional stats: mean, median, std, min, max present | ✗ | Only mean, median, std provided. Missing min/max. |\n",
      "\n",
      "---\n",
      "\n",
      "### Beverages\n",
      "\n",
      "| Requirement | Status | Notes |\n",
      "|-------------|--------|--------|\n",
      "| Identified items present | ✓ | List provided: 10 items. |\n",
      "| Price statistics JSON table present | ✓ | Table present, labeled 'PriceStatistics'. |\n",
      "| Price stats: mean, median, std, min, max present | ✓ | All required stats present (mean, median, std, min, max, count present but extra is ok). |\n",
      "| Nutritional statistics JSON table present | ✓ | Table present, labeled 'NutritionalStatistics'. |\n",
      "| Nutritional stats: mean, median, std, min, max present | ✓ | All required stats present (mean, median, std, min, max, count present but extra is ok). |\n",
      "\n",
      "---\n",
      "\n",
      "### Issues Identified\n",
      "\n",
      "#### Main Dishes:\n",
      "- **Nutritional Statistics**: **Missing required statistics: Minimum and Maximum.** Only mean, median, and standard deviation are present.\n",
      "\n",
      "---\n",
      "\n",
      "### Correction Instructions\n",
      "\n",
      "- **Main Dishes Nutritional Statistics Table**:  \n",
      "  Add the following fields, making sure you fill in their correct values:\n",
      "    - `Minimum`\n",
      "    - `Maximum`\n",
      "\n",
      "---\n",
      "\n",
      "**❌ ERROR: Main Dishes analysis failed validation.**  \n",
      "- **Nutritional statistics table** is missing `Minimum` and `Maximum`.  \n",
      "- Add these statistics to complete the analysis.  \n",
      "- Beverages analysis is correct. \n",
      "\n",
      "Please correct and resubmit.\n",
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0922f1a5",
   "metadata": {},
   "source": [
    " ## Key Takeaways\n",
    " \n",
    " ### 1. **Parallel Processing with asyncio.gather()**\n",
    " The most important concept in this notebook:\n",
    " ```python\n",
    " results = await asyncio.gather(\n",
    "     run_agent(agent1, input),\n",
    "     run_agent(agent2, input)\n",
    " )\n",
    " ```\n",
    " \n",
    " **Benefits:**\n",
    "-  **Speed**: Both agents run simultaneously, not sequentially\n",
    "-  **Scalability**: Can easily add more agents to gather()\n",
    "-  **Cost**: Same API costs as sequential, but much faster\n",
    " \n",
    " **When to Use:**\n",
    " - Agents don't depend on each other's outputs\n",
    " - Tasks can be performed independently\n",
    " - You want to minimize total execution time\n",
    " \n",
    " ### 2. **Four-Stage Pipeline Architecture**\n",
    " \n",
    " | Stage | Agent | Purpose |\n",
    " |-------|-------|---------|\n",
    " | 1. Load | CSVLoader | Import data from file |\n",
    " | 2. Analyze | MainDish + Beverage | Parallel analysis |\n",
    " | 3. Clean | CleanOutputAgent | Standardize format |\n",
    " | 4. Validate | AnalysisChecker | Quality assurance |\n",
    " \n",
    " This creates a **quality-controlled data pipeline** where:\n",
    " - Each stage has a single responsibility\n",
    " - Outputs are progressively refined\n",
    " - Final output is validated for completeness\n",
    " \n",
    " ### 3. **Separation of Concerns**\n",
    " Notice how agents are highly specialized:\n",
    " - **Loaders** only load, don't analyze\n",
    " - **Analyzers** only analyze, don't format\n",
    " - **Cleaners** only format, don't analyze or validate\n",
    " - **Validators** only check, don't modify\n",
    " \n",
    " This makes the system:\n",
    " -  Easier to test (test each stage independently)\n",
    " -  Easier to debug (isolate failures to specific stages)\n",
    " -  Easier to modify (change one agent without affecting others)\n",
    " \n",
    " ### 4. **Output Standardization**\n",
    " The CleanOutputAgent ensures:\n",
    " - Consistent JSON structure across runs\n",
    " - Removal of unnecessary explanatory text\n",
    " - Machine-readable format for downstream systems\n",
    " - Validation-ready format\n",
    " \n",
    " ### 5. **Quality Validation Pattern**\n",
    " The AnalysisChecker implements a **quality gate**:\n",
    " - Verifies completeness (all required fields present)\n",
    " - Checks correctness (data in expected format)\n",
    " - Provides actionable feedback on failures\n",
    " - Acts as final quality control before output delivery\n",
    " \n",
    " ### 6. **Performance Comparison**\n",
    " \n",
    " **Sequential Processing:**\n",
    " ```\n",
    " Time = Load + Analyze1 + Analyze2 + Clean + Validate\n",
    " Time = 2s + 8s + 8s + 3s + 2s = 23s\n",
    " ```\n",
    " \n",
    " **Parallel Processing (this approach):**\n",
    " ```\n",
    " Time = Load + max(Analyze1, Analyze2) + Clean + Validate\n",
    " Time = 2s + max(8s, 8s) + 3s + 2s = 15s\n",
    " Speedup: 35% faster! ⚡\n",
    " ```\n",
    " \n",
    " ### 7. **Production Enhancements**\n",
    " \n",
    " **Error Handling:**\n",
    " ```python\n",
    " try:\n",
    "     results = await asyncio.gather(\n",
    "         run_agent(agent1, input),\n",
    "         run_agent(agent2, input),\n",
    "         return_exceptions=True  # Don't fail entire batch\n",
    "     )\n",
    " except Exception as e:\n",
    "     handle_error(e)\n",
    " ```\n",
    " \n",
    " **Retry Logic:**\n",
    " ```python\n",
    " async def run_agent_with_retry(agent, input, max_retries=3):\n",
    "     for attempt in range(max_retries):\n",
    "         try:\n",
    "             return await run_agent(agent, input)\n",
    "         except Exception:\n",
    "             if attempt == max_retries - 1:\n",
    "                 raise\n",
    "             await asyncio.sleep(2 ** attempt)\n",
    " ```\n",
    " \n",
    " **Progress Tracking:**\n",
    " ```python\n",
    " from tqdm.asyncio import tqdm\n",
    " \n",
    " results = await tqdm.gather(\n",
    "     run_agent(agent1, input),\n",
    "     run_agent(agent2, input),\n",
    "     desc=\"Analyzing\"\n",
    " )\n",
    " ```\n",
    " \n",
    " **Caching:**\n",
    " ```python\n",
    " from functools import lru_cache\n",
    " \n",
    " @lru_cache(maxsize=100)\n",
    " def load_csv_file(file_path):\n",
    "     # Cache expensive file I/O operations\n",
    "     pass\n",
    " ```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
