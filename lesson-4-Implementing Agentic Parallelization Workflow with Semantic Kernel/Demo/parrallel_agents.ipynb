{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c697a75",
   "metadata": {},
   "source": [
    "# Multi-Agent Restaurant Menu Analytics System\n",
    " \n",
    "## Overview\n",
    " This notebook demonstrates **parallel agent processing** with data validation. Multiple specialized agents analyze different aspects of restaurant menu data simultaneously, their outputs are cleaned and standardized, then validated for quality assurance.\n",
    "\n",
    " <div align=\"center\">\n",
    "<img src=\"lesson_4.png\" alt=\"Alt text\" width=\"550\"/>\n",
    "</div>\n",
    " \n",
    " ### Key Concepts Covered:\n",
    " 1. **Parallel Agent Execution**: Multiple agents process data simultaneously using `asyncio.gather()`\n",
    " 2. **Data Loading Agent**: Specialized agent for file I/O operations\n",
    " 3. **Domain-Specific Analyzers**: Agents with narrow analytical focus\n",
    " 4. **Output Standardization**: Cleaning agent formats raw outputs into consistent structure\n",
    " 5. **Quality Validation**: Checker agent validates completeness and accuracy\n",
    " 6. **Pipeline Architecture**: Data flows through distinct processing stages\n",
    "\n",
    " ## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b947019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a74d8b",
   "metadata": {},
   "source": [
    " ## 2. Define Agent Instructions\n",
    " \n",
    " Each agent has precise instructions defining its role, behavior, and output format.\n",
    " This ensures consistent, predictable agent behavior.\n",
    "\n",
    " ### 2.1 CSV Loader Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754f7d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Loader_Name = \"CSVLoader\"\n",
    "CSV_Loader_Instructions = \"\"\"\n",
    "    You are a CSV Loader Agent.\n",
    "    Your role is to read menu data from a CSV file, extract its contents, and return it as a clean, comma-separated string.\n",
    "    You do not perform analysis — only data loading and formatting.\n",
    "    Keep the output concise and ready for downstream analysis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2ebab",
   "metadata": {},
   "source": [
    " ### 2.2 Main Dish Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76178beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main_Dish_Analyzer_Name = \"MainDishAnalyzer\"\n",
    "Main_Dish_Analyzer_Instructions = \"\"\"\n",
    "    AI Agent Persona: Main Dish Analytics Assistant\n",
    "    Role: A specialized assistant focused exclusively on analyzing main dish menu items and calculating descriptive statistics.\n",
    "    Behavior: The agent does not answer questions outside the scope of main dish analysis.\n",
    "    Response Style: Always provide calculated results clearly and concisely.\n",
    "    \n",
    "    Agent Instructions:\n",
    "    From the restaurant menu dataset provided, extract the MAIN DISHES and analyze these items only.\n",
    "    Main dishes include: pasta, steak, chicken, fish, burgers, pizza, risotto, lamb, pork, seafood entrees.\n",
    "    \n",
    "    Calculate descriptive statistics including:\n",
    "    - Mean, median, standard deviation, minimum, and maximum for price\n",
    "    - Mean, median, standard deviation for calories (if available)\n",
    "    - Count of items in this category\n",
    "    \n",
    "    Ensure all calculations are based on cleaned data (after removing any anomalies or outliers).\n",
    "    Present the results in a clear, structured format for immediate interpretation.\n",
    "    \n",
    "    Descriptive statistics MUST be presented in JSON format, with two tables:\n",
    "    1. Price Statistics Table\n",
    "    2. Nutritional Statistics Table (calories, etc.)\n",
    "    Add clear titles to the JSON tables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7f8dc",
   "metadata": {},
   "source": [
    " ### 2.3 Beverage Analyzer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ccb07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Beverage_Analyzer_Name = \"BeverageAnalyzer\"\n",
    "Beverage_Analyzer_Instructions = \"\"\"\n",
    "    AI Agent Persona: Beverage Analytics Assistant\n",
    "    Role: A specialized assistant focused exclusively on analyzing beverage menu items and calculating descriptive statistics.\n",
    "    Behavior: The agent does not answer questions outside the scope of beverage analysis.\n",
    "    Response Style: Always provide calculated results clearly and concisely.\n",
    "    \n",
    "    Agent Instructions:\n",
    "    From the restaurant menu dataset provided, extract the BEVERAGES and analyze these items only.\n",
    "    Beverages include: coffee, tea, juice, soda, wine, beer, cocktails, smoothies, milkshakes, water.\n",
    "    \n",
    "    Calculate descriptive statistics including:\n",
    "    - Mean, median, standard deviation, minimum, and maximum for price\n",
    "    - Mean, median, standard deviation for calories (if available)\n",
    "    - Count of items in this category\n",
    "    \n",
    "    Ensure all calculations are based on cleaned data (after removing any anomalies or outliers).\n",
    "    Present the results in a clear, structured format for immediate interpretation.\n",
    "    \n",
    "    Descriptive statistics MUST be presented in JSON format, with two tables:\n",
    "    1. Price Statistics Table\n",
    "    2. Nutritional Statistics Table (calories, etc.)\n",
    "    Add clear titles to the JSON tables.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d57686",
   "metadata": {},
   "source": [
    " ### 2.4 Output Cleaning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91df610",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_Output_Agent_Name = \"CleanOutputAgent\"\n",
    "Clean_Output_Agent_Instructions = \"\"\"\n",
    "    AI Agent Persona: Output Cleaning Specialist\n",
    "    Role: To process and sanitize the raw outputs from analysis agents.\n",
    "    Behavior: You do not perform new analysis — you only extract and format existing results.\n",
    "    Response Style: Always output in a clean, minimal, structured format.\n",
    "\n",
    "    Cleaning Tasks:\n",
    "    1. From each analyzer's output, extract:\n",
    "       - The list of identified menu items\n",
    "       - The JSON table for price statistics\n",
    "       - The JSON table for nutritional statistics\n",
    "    2. Remove any unrelated text, explanations, commentary, or markdown formatting.\n",
    "    3. Present the cleaned data in the following standardized JSON structure:\n",
    "\n",
    "    {\n",
    "        \"MainDishes\": {\n",
    "            \"IdentifiedItems\": [...],\n",
    "            \"PriceStatistics\": {...},\n",
    "            \"NutritionalStatistics\": {...}\n",
    "        },\n",
    "        \"Beverages\": {\n",
    "            \"IdentifiedItems\": [...],\n",
    "            \"PriceStatistics\": {...},\n",
    "            \"NutritionalStatistics\": {...}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Output ONLY valid JSON. No explanations, no markdown, no additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80154332",
   "metadata": {},
   "source": [
    " ### 2.5 Analysis Validation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f34598",
   "metadata": {},
   "outputs": [],
   "source": [
    "Analysis_Checker_Name = \"AnalysisChecker\"\n",
    "Analysis_Checker_Instructions = \"\"\"\n",
    "    AI Agent Persona: Data Analysis Validation Auditor\n",
    "    Role: A specialized agent responsible for verifying that analytics tasks are completed correctly by other agents.\n",
    "    Behavior: The agent does not perform analysis itself but evaluates the completeness and accuracy of other agents' outputs.\n",
    "    Response Style: Always provide a clear, structured validation report or approval.\n",
    "\n",
    "    Validation Tasks:\n",
    "    1. Verify Main Dish Analysis:\n",
    "         Main dish items are identified\n",
    "         Two JSON tables are present: one for price statistics and one for nutritional statistics\n",
    "         All required statistics are present (mean, median, std, min, max)\n",
    "        \n",
    "    2. Verify Beverage Analysis:\n",
    "         Beverage items are identified\n",
    "         Two JSON tables are present: one for price statistics and one for nutritional statistics\n",
    "         All required statistics are present (mean, median, std, min, max)\n",
    "\n",
    "    Decision Logic:\n",
    "    - If BOTH analyses meet ALL criteria → output: \"APPROVED: All analyses complete and valid.\"\n",
    "    - If EITHER analysis fails ANY check → output a detailed error message specifying:\n",
    "      * Which category failed (Main Dishes or Beverages)\n",
    "      * Which specific requirement was not met\n",
    "      * What needs to be corrected\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505cc9d1",
   "metadata": {},
   "source": [
    " ## 3. Load Environment and Initialize Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d49982",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "url = os.getenv(\"URL\")\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "# Create kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Configure Azure OpenAI service\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=\"none\", \n",
    "    api_key=api_key,\n",
    "    base_url=url,\n",
    "    api_version=api_version\n",
    ")\n",
    "\n",
    "# Register service with kernel\n",
    "kernel.add_service(chat_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb6bab2",
   "metadata": {},
   "source": [
    " ## 4. Instantiate All Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19787e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_csv_loader = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=CSV_Loader_Name,\n",
    "    instructions=CSV_Loader_Instructions,\n",
    ")\n",
    "\n",
    "agent_main_dish_analyzer = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Main_Dish_Analyzer_Name,\n",
    "    instructions=Main_Dish_Analyzer_Instructions,\n",
    ")\n",
    "\n",
    "agent_beverage_analyzer = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Beverage_Analyzer_Name,\n",
    "    instructions=Beverage_Analyzer_Instructions,\n",
    ")\n",
    "\n",
    "agent_clean_output = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Clean_Output_Agent_Name,\n",
    "    instructions=Clean_Output_Agent_Instructions,\n",
    ")\n",
    "\n",
    "agent_checker = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Analysis_Checker_Name,\n",
    "    instructions=Analysis_Checker_Instructions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172108fc",
   "metadata": {},
   "source": [
    " ## 5. Helper Functions\n",
    "\n",
    "  ### 5.1 Agent Execution Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b363fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agent(agent, task_input):\n",
    "    \"\"\"\n",
    "    Executes an agent and collects all output messages.\n",
    "    \n",
    "    Args:\n",
    "        agent: The ChatCompletionAgent to invoke\n",
    "        task_input: The input prompt/data for the agent\n",
    "    \n",
    "    Returns:\n",
    "        List of message objects from the agent\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    async for message in agent.invoke(task_input):\n",
    "        outputs.append(message)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0912d1c",
   "metadata": {},
   "source": [
    " ### 5.2 CSV Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a74544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads a CSV file and converts it to a flat comma-separated string.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "        String representation of CSV data\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Flatten the dataframe and join as comma-separated string\n",
    "    flat_data = \", \".join(map(str, df.values.flatten()))\n",
    "    return flat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cf4e41",
   "metadata": {},
   "source": [
    " ## 6. Parallel Analysis Function\n",
    " \n",
    " This is the **key**: using `asyncio.gather()` to run multiple agents simultaneously.\n",
    " This dramatically reduces total processing time compared to sequential execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d71262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parallel_analysis(task_input: str):\n",
    "    \"\"\"\n",
    "    Runs multiple analyzer agents in parallel using asyncio.gather().\n",
    "    \n",
    "    This approach is much faster than sequential execution:\n",
    "    - Sequential: Time = T1 + T2\n",
    "    - Parallel: Time ≈ max(T1, T2)\n",
    "    \n",
    "    Args:\n",
    "        task_input: The data to be analyzed\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results from both analyzers\n",
    "    \"\"\"\n",
    "    # Execute both agents simultaneously\n",
    "    results = await asyncio.gather(\n",
    "        run_agent(agent_main_dish_analyzer, task_input),\n",
    "        run_agent(agent_beverage_analyzer, task_input)\n",
    "    )\n",
    "    \n",
    "    # Package results into structured dictionary\n",
    "    merged_output = {\n",
    "        \"MainDishAnalyzer\": results[0][0].content,\n",
    "        \"BeverageAnalyzer\": results[1][0].content\n",
    "    }\n",
    "    return merged_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487affa5",
   "metadata": {},
   "source": [
    " ## 7. Main Processing Pipeline\n",
    " \n",
    " This demonstrates the complete **four-stage pipeline**:\n",
    " 1. **Load**: Read data from CSV\n",
    " 2. **Analyze**: Parallel processing by specialized agents\n",
    " 3. **Clean**: Standardize outputs into consistent format\n",
    " 4. **Validate**: Quality check by validation agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e081adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the complete restaurant menu analytics pipeline.\n",
    "    \n",
    "    Pipeline Stages:\n",
    "    Stage 1: Data Loading\n",
    "    Stage 2: Parallel Analysis (Main Dishes + Beverages)\n",
    "    Stage 3: Output Cleaning and Standardization\n",
    "    Stage 4: Validation and Quality Assurance\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"RESTAURANT MENU ANALYTICS SYSTEM\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # ==================== STAGE 1: DATA LOADING ====================\n",
    "    print(\"\\nSTAGE 1: Loading CSV Data\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    csv_path = \"restaurant_menu.csv\"  # Change to your CSV file path\n",
    "    csv_data = load_csv_file(csv_path)\n",
    "    print(f\"CSV data loaded successfully\")\n",
    "    print(f\"Data preview: {csv_data[:200]}...\\n\")\n",
    "    \n",
    "    # ==================== STAGE 2: PARALLEL ANALYSIS ====================\n",
    "    print(\" STAGE 2: Running Parallel Analysis\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"MainDishAnalyzer and BeverageAnalyzer executing simultaneously...\")\n",
    "    \n",
    "    raw_results = await parallel_analysis(f\"Analyze this restaurant menu data: {csv_data}\")\n",
    "    \n",
    "    print(\"\\nAnalysis complete!\")\n",
    "    print(\"\\nRAW ANALYZER OUTPUTS:\")\n",
    "    print(\"-\" * 70)\n",
    "    for analyzer, output in raw_results.items():\n",
    "        print(f\"\\n[{analyzer}]\")\n",
    "        print(output)\n",
    "    \n",
    "    # ==================== STAGE 3: OUTPUT CLEANING ====================\n",
    "    print(\"\\n\\nSTAGE 3: Cleaning and Standardizing Outputs\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    clean_input = f\"Clean the following outputs: {raw_results}\"\n",
    "    clean_result = await run_agent(agent_clean_output, clean_input)\n",
    "    cleaned_output = clean_result[0].content\n",
    "    \n",
    "    print(\"Output cleaned and standardized\")\n",
    "    print(\"\\nCLEANED OUTPUT:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(cleaned_output)\n",
    "    \n",
    "    # ==================== STAGE 4: VALIDATION ====================\n",
    "    print(\"\\n\\nSTAGE 4: Validating Analysis Quality\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    checker_result = await run_agent(\n",
    "        agent_checker, \n",
    "        f\"Check this cleaned output for completeness and accuracy: {cleaned_output}\"\n",
    "    )\n",
    "    \n",
    "    print(\"VALIDATION RESULT:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(checker_result[0].content)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PIPELINE COMPLETE\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824ef809",
   "metadata": {},
   "source": [
    " ## 8. Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7bec4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESTAURANT MENU ANALYTICS SYSTEM\n",
      "======================================================================\n",
      "\n",
      "STAGE 1: Loading CSV Data\n",
      "----------------------------------------------------------------------\n",
      "CSV data loaded successfully\n",
      "Data preview: MENU5506, Spaghetti Carbonara, pasta, 17.46, 720, True, MENU2679, Fettuccine Alfredo, pasta, 15.17, 680, True, MENU2424, Penne Arrabbiata, pasta, 15.52, 620, False, MENU1488, Lasagna Bolognese, pasta,...\n",
      "\n",
      " STAGE 2: Running Parallel Analysis\n",
      "----------------------------------------------------------------------\n",
      "MainDishAnalyzer and BeverageAnalyzer executing simultaneously...\n",
      "\n",
      "Analysis complete!\n",
      "\n",
      "RAW ANALYZER OUTPUTS:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[MainDishAnalyzer]\n",
      "{\n",
      "  \"Price Statistics Table\": {\n",
      "    \"title\": \"Main Dish Price Statistics\",\n",
      "    \"count\": 32,\n",
      "    \"mean\": 22.38,\n",
      "    \"median\": 18.96,\n",
      "    \"std_dev\": 8.67,\n",
      "    \"min\": 12.65,\n",
      "    \"max\": 42.40\n",
      "  },\n",
      "  \"Nutritional Statistics Table\": {\n",
      "    \"title\": \"Main Dish Calories Statistics\",\n",
      "    \"count\": 32,\n",
      "    \"mean\": 666.56,\n",
      "    \"median\": 680,\n",
      "    \"std_dev\": 145.69\n",
      "  }\n",
      "}\n",
      "\n",
      "**Main Dish Items Analyzed:**  \n",
      "Pasta (Spaghetti Carbonara, Fettuccine Alfredo, Penne Arrabbiata, Lasagna Bolognese, Linguine with Clams)  \n",
      "Steak (Ribeye, Filet Mignon, New York Strip, Sirloin)  \n",
      "Chicken (Grilled Chicken Breast, Chicken Parmesan, Chicken Marsala, BBQ Chicken)  \n",
      "Fish (Grilled Salmon, Pan-Seared Sea Bass, Tuna Steak, Fish and Chips)  \n",
      "Burger (Classic Cheeseburger, Bacon Burger, Mushroom Swiss Burger, Veggie Burger)  \n",
      "Pizza (Margherita, Pepperoni, BBQ Chicken, Vegetarian)  \n",
      "Lamb (Lamb Chops)  \n",
      "Pork (Pork Tenderloin)  \n",
      "Seafood (Lobster Tail, Shrimp Scampi)  \n",
      "Risotto (Mushroom Risotto)\n",
      "\n",
      "**All statistics based on cleaned, non-beverage, non-dessert, main dish items only.**\n",
      "\n",
      "[BeverageAnalyzer]\n",
      "{\n",
      "  \"Price Statistics Table\": {\n",
      "    \"title\": \"Descriptive Price Statistics for Beverages\",\n",
      "    \"count\": 31,\n",
      "    \"mean\": 6.964,\n",
      "    \"median\": 5.54,\n",
      "    \"std_dev\": 3.089,\n",
      "    \"min\": 1.87,\n",
      "    \"max\": 13.54\n",
      "  },\n",
      "  \"Nutritional Statistics Table\": {\n",
      "    \"title\": \"Descriptive Calorie Statistics for Beverages\",\n",
      "    \"count\": 31,\n",
      "    \"mean\": 132.58,\n",
      "    \"median\": 120,\n",
      "    \"std_dev\": 116.90,\n",
      "    \"min\": 0,\n",
      "    \"max\": 520\n",
      "  }\n",
      "}\n",
      "\n",
      "**Notes**:\n",
      "- Outliers and data anomalies were checked, and all values were reasonable for beverage price and calories.\n",
      "- The analysis includes all items in the beverage categories: coffee, tea, juice, soda, wine, beer, cocktails, smoothies, milkshakes, and water, per your criteria.\n",
      "\n",
      "\n",
      "STAGE 3: Cleaning and Standardizing Outputs\n",
      "----------------------------------------------------------------------\n",
      "Output cleaned and standardized\n",
      "\n",
      "CLEANED OUTPUT:\n",
      "----------------------------------------------------------------------\n",
      "{\n",
      "    \"MainDishes\": {\n",
      "        \"IdentifiedItems\": [\n",
      "            \"Spaghetti Carbonara\",\n",
      "            \"Fettuccine Alfredo\",\n",
      "            \"Penne Arrabbiata\",\n",
      "            \"Lasagna Bolognese\",\n",
      "            \"Linguine with Clams\",\n",
      "            \"Ribeye\",\n",
      "            \"Filet Mignon\",\n",
      "            \"New York Strip\",\n",
      "            \"Sirloin\",\n",
      "            \"Grilled Chicken Breast\",\n",
      "            \"Chicken Parmesan\",\n",
      "            \"Chicken Marsala\",\n",
      "            \"BBQ Chicken\",\n",
      "            \"Grilled Salmon\",\n",
      "            \"Pan-Seared Sea Bass\",\n",
      "            \"Tuna Steak\",\n",
      "            \"Fish and Chips\",\n",
      "            \"Classic Cheeseburger\",\n",
      "            \"Bacon Burger\",\n",
      "            \"Mushroom Swiss Burger\",\n",
      "            \"Veggie Burger\",\n",
      "            \"Margherita Pizza\",\n",
      "            \"Pepperoni Pizza\",\n",
      "            \"BBQ Chicken Pizza\",\n",
      "            \"Vegetarian Pizza\",\n",
      "            \"Lamb Chops\",\n",
      "            \"Pork Tenderloin\",\n",
      "            \"Lobster Tail\",\n",
      "            \"Shrimp Scampi\",\n",
      "            \"Mushroom Risotto\"\n",
      "        ],\n",
      "        \"PriceStatistics\": {\n",
      "            \"title\": \"Main Dish Price Statistics\",\n",
      "            \"count\": 32,\n",
      "            \"mean\": 22.38,\n",
      "            \"median\": 18.96,\n",
      "            \"std_dev\": 8.67,\n",
      "            \"min\": 12.65,\n",
      "            \"max\": 42.40\n",
      "        },\n",
      "        \"NutritionalStatistics\": {\n",
      "            \"title\": \"Main Dish Calories Statistics\",\n",
      "            \"count\": 32,\n",
      "            \"mean\": 666.56,\n",
      "            \"median\": 680,\n",
      "            \"std_dev\": 145.69\n",
      "        }\n",
      "    },\n",
      "    \"Beverages\": {\n",
      "        \"IdentifiedItems\": [\n",
      "            \"coffee\",\n",
      "            \"tea\",\n",
      "            \"juice\",\n",
      "            \"soda\",\n",
      "            \"wine\",\n",
      "            \"beer\",\n",
      "            \"cocktails\",\n",
      "            \"smoothies\",\n",
      "            \"milkshakes\",\n",
      "            \"water\"\n",
      "        ],\n",
      "        \"PriceStatistics\": {\n",
      "            \"title\": \"Descriptive Price Statistics for Beverages\",\n",
      "            \"count\": 31,\n",
      "            \"mean\": 6.964,\n",
      "            \"median\": 5.54,\n",
      "            \"std_dev\": 3.089,\n",
      "            \"min\": 1.87,\n",
      "            \"max\": 13.54\n",
      "        },\n",
      "        \"NutritionalStatistics\": {\n",
      "            \"title\": \"Descriptive Calorie Statistics for Beverages\",\n",
      "            \"count\": 31,\n",
      "            \"mean\": 132.58,\n",
      "            \"median\": 120,\n",
      "            \"std_dev\": 116.90,\n",
      "            \"min\": 0,\n",
      "            \"max\": 520\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "STAGE 4: Validating Analysis Quality\n",
      "----------------------------------------------------------------------\n",
      "VALIDATION RESULT:\n",
      "----------------------------------------------------------------------\n",
      "Validation Report:\n",
      "\n",
      "1. Main Dish Analysis\n",
      "\n",
      "    a. Identified Items: PRESENT\n",
      "        - 29 main dish items listed (count value states 32, mismatch detected)\n",
      "    b. Price Statistics: PRESENT\n",
      "        - JSON table includes: mean, median, std_dev, min, max, count [OK]\n",
      "    c. Nutritional Statistics: PRESENT\n",
      "        - JSON table includes: mean, median, std_dev [MISSING min, max]\n",
      "        - count value matches price statistics (32), but only 29 items listed [INCONSISTENT]\n",
      "\n",
      "2. Beverage Analysis\n",
      "\n",
      "    a. Identified Items: PRESENT\n",
      "        - 10 beverage items listed (count value states 31, mismatch detected)\n",
      "    b. Price Statistics: PRESENT\n",
      "        - JSON table includes: mean, median, std_dev, min, max, count [OK]\n",
      "    c. Nutritional Statistics: PRESENT\n",
      "        - JSON table includes: mean, median, std_dev, min, max, count [OK]\n",
      "\n",
      "Summary of Issues:\n",
      "\n",
      "- **Main Dishes**\n",
      "    - Item count in \"IdentifiedItems\" (29) does not match \"count\" in statistics (32)\n",
      "    - \"NutritionalStatistics\" for main dishes lacks \"min\" and \"max\" values\n",
      "\n",
      "- **Beverages**\n",
      "    - Item count in \"IdentifiedItems\" (10) does not match \"count\" in statistics (31)\n",
      "\n",
      "Required Corrections:\n",
      "\n",
      "1. Main Dishes:\n",
      "    - Ensure \"IdentifiedItems\" list matches the count used in statistics (either add missing items or adjust \"count\")\n",
      "    - Add \"min\" and \"max\" values to the \"NutritionalStatistics\" JSON for main dishes\n",
      "\n",
      "2. Beverages:\n",
      "    - Ensure \"IdentifiedItems\" list matches the count used in statistics (either add missing items or adjust \"count\")\n",
      "\n",
      "ERROR: Analyses are INCOMPLETE/INACCURATE.\n",
      "- Main Dishes: Count inconsistency and missing nutritional statistics (min/max)\n",
      "- Beverages: Count inconsistency\n",
      "Please correct these issues and resubmit.\n",
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41a0e36",
   "metadata": {},
   "source": [
    "# Using Semantic Kernel Concurrent Orchestration\n",
    "\n",
    "## 1. Sepup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eda9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d51ca",
   "metadata": {},
   "source": [
    "## 2. Define Agent Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "649c30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Loader_Name = \"CSVLoader\"\n",
    "CSV_Loader_Instructions = \"\"\"\n",
    "    You are a CSV Loader Agent.\n",
    "    Your role is to read menu data from a CSV file, extract its contents, and return it as a clean, comma-separated string.\n",
    "    You do not perform analysis — only data loading and formatting.\n",
    "    Keep the output concise and ready for downstream analysis.\n",
    "\"\"\"\n",
    "\n",
    "Main_Dish_Analyzer_Name = \"MainDishAnalyzer\"\n",
    "Main_Dish_Analyzer_Instructions = \"\"\"\n",
    "    AI Agent Persona: Main Dish Analytics Assistant\n",
    "    Role: A specialized assistant focused exclusively on analyzing main dish menu items and calculating descriptive statistics.\n",
    "    Behavior: The agent does not answer questions outside the scope of main dish analysis.\n",
    "    Response Style: Always provide calculated results clearly and concisely.\n",
    "    \n",
    "    Agent Instructions:\n",
    "    From the restaurant menu dataset provided, extract the MAIN DISHES and analyze these items only.\n",
    "    Main dishes include: pasta, steak, chicken, fish, burgers, pizza, risotto, lamb, pork, seafood entrees.\n",
    "    \n",
    "    Calculate descriptive statistics including:\n",
    "    - Mean, median, standard deviation, minimum, and maximum for price\n",
    "    - Mean, median, standard deviation for calories (if available)\n",
    "    - Count of items in this category\n",
    "    \n",
    "    Ensure all calculations are based on cleaned data (after removing any anomalies or outliers).\n",
    "    Present the results in a clear, structured format for immediate interpretation.\n",
    "    \n",
    "    Descriptive statistics MUST be presented in JSON format, with two tables:\n",
    "    1. Price Statistics Table\n",
    "    2. Nutritional Statistics Table (calories, etc.)\n",
    "    Add clear titles to the JSON tables.\n",
    "\"\"\"\n",
    "\n",
    "Beverage_Analyzer_Name = \"BeverageAnalyzer\"\n",
    "Beverage_Analyzer_Instructions = \"\"\"\n",
    "    AI Agent Persona: Beverage Analytics Assistant\n",
    "    Role: A specialized assistant focused exclusively on analyzing beverage menu items and calculating descriptive statistics.\n",
    "    Behavior: The agent does not answer questions outside the scope of beverage analysis.\n",
    "    Response Style: Always provide calculated results clearly and concisely.\n",
    "    \n",
    "    Agent Instructions:\n",
    "    From the restaurant menu dataset provided, extract the BEVERAGES and analyze these items only.\n",
    "    Beverages include: coffee, tea, juice, soda, wine, beer, cocktails, smoothies, milkshakes, water.\n",
    "    \n",
    "    Calculate descriptive statistics including:\n",
    "    - Mean, median, standard deviation, minimum, and maximum for price\n",
    "    - Mean, median, standard deviation for calories (if available)\n",
    "    - Count of items in this category\n",
    "    \n",
    "    Ensure all calculations are based on cleaned data (after removing any anomalies or outliers).\n",
    "    Present the results in a clear, structured format for immediate interpretation.\n",
    "    \n",
    "    Descriptive statistics MUST be presented in JSON format, with two tables:\n",
    "    1. Price Statistics Table\n",
    "    2. Nutritional Statistics Table (calories, etc.)\n",
    "    Add clear titles to the JSON tables.\n",
    "\"\"\"\n",
    "\n",
    "Clean_Output_Agent_Name = \"CleanOutputAgent\"\n",
    "Clean_Output_Agent_Instructions = \"\"\"\n",
    "    AI Agent Persona: Output Cleaning Specialist\n",
    "    Role: To process and sanitize the raw outputs from analysis agents.\n",
    "    Behavior: You do not perform new analysis — you only extract and format existing results.\n",
    "    Response Style: Always output in a clean, minimal, structured format.\n",
    "\n",
    "    Cleaning Tasks:\n",
    "    1. From each analyzer's output, extract:\n",
    "       - The list of identified menu items\n",
    "       - The JSON table for price statistics\n",
    "       - The JSON table for nutritional statistics\n",
    "    2. Remove any unrelated text, explanations, commentary, or markdown formatting.\n",
    "    3. Present the cleaned data in the following standardized JSON structure:\n",
    "\n",
    "    {\n",
    "        \"MainDishes\": {\n",
    "            \"IdentifiedItems\": [...],\n",
    "            \"PriceStatistics\": {...},\n",
    "            \"NutritionalStatistics\": {...}\n",
    "        },\n",
    "        \"Beverages\": {\n",
    "            \"IdentifiedItems\": [...],\n",
    "            \"PriceStatistics\": {...},\n",
    "            \"NutritionalStatistics\": {...}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    Output ONLY valid JSON. No explanations, no markdown, no additional text.\n",
    "\"\"\"\n",
    "\n",
    "Analysis_Checker_Name = \"AnalysisChecker\"\n",
    "Analysis_Checker_Instructions = \"\"\"\n",
    "    AI Agent Persona: Data Analysis Validation Auditor\n",
    "    Role: A specialized agent responsible for verifying that analytics tasks are completed correctly by other agents.\n",
    "    Behavior: The agent does not perform analysis itself but evaluates the completeness and accuracy of other agents' outputs.\n",
    "    Response Style: Always provide a clear, structured validation report or approval.\n",
    "\n",
    "    Validation Tasks:\n",
    "    1. Verify Main Dish Analysis:\n",
    "         Main dish items are identified\n",
    "         Two JSON tables are present: one for price statistics and one for nutritional statistics\n",
    "         All required statistics are present (mean, median, std, min, max)\n",
    "        \n",
    "    2. Verify Beverage Analysis:\n",
    "         Beverage items are identified\n",
    "         Two JSON tables are present: one for price statistics and one for nutritional statistics\n",
    "         All required statistics are present (mean, median, std, min, max)\n",
    "\n",
    "    Decision Logic:\n",
    "    - If BOTH analyses meet ALL criteria → output: \"APPROVED: All analyses complete and valid.\"\n",
    "    - If EITHER analysis fails ANY check → output a detailed error message specifying:\n",
    "      * Which category failed (Main Dishes or Beverages)\n",
    "      * Which specific requirement was not met\n",
    "      * What needs to be corrected\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de383b5",
   "metadata": {},
   "source": [
    "## 3. Load Environment and Initialize Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b29b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "url = os.getenv(\"URL\")\n",
    "api_version = \"2024-12-01-preview\"\n",
    "\n",
    "# Create kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Configure Azure OpenAI service\n",
    "chat_service = AzureChatCompletion(\n",
    "    deployment_name=\"none\", \n",
    "    api_key=api_key,\n",
    "    base_url=url,\n",
    "    api_version=api_version\n",
    ")\n",
    "\n",
    "# Register service with kernel\n",
    "kernel.add_service(chat_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abb392",
   "metadata": {},
   "source": [
    "## 4. Instantiate All Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ee700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_csv_loader = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=CSV_Loader_Name,\n",
    "    instructions=CSV_Loader_Instructions,\n",
    ")\n",
    "\n",
    "agent_main_dish_analyzer = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Main_Dish_Analyzer_Name,\n",
    "    instructions=Main_Dish_Analyzer_Instructions,\n",
    ")\n",
    "\n",
    "agent_beverage_analyzer = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Beverage_Analyzer_Name,\n",
    "    instructions=Beverage_Analyzer_Instructions,\n",
    ")\n",
    "\n",
    "agent_clean_output = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Clean_Output_Agent_Name,\n",
    "    instructions=Clean_Output_Agent_Instructions,\n",
    ")\n",
    "\n",
    "agent_checker = ChatCompletionAgent(\n",
    "    service=chat_service,\n",
    "    name=Analysis_Checker_Name,\n",
    "    instructions=Analysis_Checker_Instructions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a13676",
   "metadata": {},
   "source": [
    " ## 5. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "055d762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_agent(agent, task_input):\n",
    "    \"\"\"\n",
    "    Executes an agent and collects all output messages.\n",
    "    \n",
    "    Args:\n",
    "        agent: The ChatCompletionAgent to invoke\n",
    "        task_input: The input prompt/data for the agent\n",
    "    \n",
    "    Returns:\n",
    "        List of message objects from the agent\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    async for message in agent.invoke(task_input):\n",
    "        outputs.append(message)\n",
    "    return outputs\n",
    "\n",
    "def load_csv_file(file_path):\n",
    "    \"\"\"\n",
    "    Loads a CSV file and converts it to a flat comma-separated string.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "        String representation of CSV data\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Flatten the dataframe and join as comma-separated string\n",
    "    flat_data = \", \".join(map(str, df.values.flatten()))\n",
    "    return flat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9e424",
   "metadata": {},
   "source": [
    "## 6. Define an Array with Parallel Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7205b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [agent_main_dish_analyzer, agent_beverage_analyzer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d603944",
   "metadata": {},
   "source": [
    "## 7. Instantiate Concurrent Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee115636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents import ConcurrentOrchestration\n",
    "\n",
    "concurrent_orchestration = ConcurrentOrchestration(members=agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0c5ca",
   "metadata": {},
   "source": [
    "## 8. Instantiate and start Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34f4d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "\n",
    "runtime = InProcessRuntime()\n",
    "runtime.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2999c2f2",
   "metadata": {},
   "source": [
    "## 9. New Paralell Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9465c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the complete restaurant menu analytics pipeline.\n",
    "    \n",
    "    Pipeline Stages:\n",
    "    Stage 1: Data Loading\n",
    "    Stage 2: Parallel Analysis (Main Dishes + Beverages)\n",
    "    Stage 3: Output Cleaning and Standardization\n",
    "    Stage 4: Validation and Quality Assurance\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"RESTAURANT MENU ANALYTICS SYSTEM\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # ==================== STAGE 1: DATA LOADING ====================\n",
    "    print(\"\\nSTAGE 1: Loading CSV Data\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    csv_path = \"restaurant_menu.csv\"  # Change to your CSV file path\n",
    "    csv_data = load_csv_file(csv_path)\n",
    "    print(f\"CSV data loaded successfully\")\n",
    "    print(f\"Data preview: {csv_data[:200]}...\\n\")\n",
    "    \n",
    "    # ==================== STAGE 2: PARALLEL ANALYSIS ====================\n",
    "    print(\" STAGE 2: Running Parallel Analysis\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"MainDishAnalyzer and BeverageAnalyzer executing simultaneously...\")\n",
    "\n",
    "    orchestration_result = await concurrent_orchestration.invoke(\n",
    "        task=f\"Analyze this restaurant menu data: {csv_data}\",\n",
    "        runtime=runtime,\n",
    "    )\n",
    "    raw_results = await orchestration_result.get(timeout=20)\n",
    "\n",
    "    print(\"\\nAnalysis complete!\")\n",
    "    print(\"\\nRAW ANALYZER OUTPUTS:\")\n",
    "    print(\"-\" * 70)\n",
    "    for item in raw_results:\n",
    "        print(f\"# {item.name}: {item.content}\")\n",
    "    \n",
    "    # ==================== STAGE 3: OUTPUT CLEANING ====================\n",
    "    print(\"\\n\\nSTAGE 3: Cleaning and Standardizing Outputs\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    clean_input = f\"Clean the following outputs: {raw_results}\"\n",
    "    clean_result = await run_agent(agent_clean_output, clean_input)\n",
    "    cleaned_output = clean_result[0].content\n",
    "    \n",
    "    print(\"Output cleaned and standardized\")\n",
    "    print(\"\\nCLEANED OUTPUT:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(cleaned_output)\n",
    "    \n",
    "    # ==================== STAGE 4: VALIDATION ====================\n",
    "    print(\"\\n\\nSTAGE 4: Validating Analysis Quality\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    checker_result = await run_agent(\n",
    "        agent_checker, \n",
    "        f\"Check this cleaned output for completeness and accuracy: {cleaned_output}\"\n",
    "    )\n",
    "    \n",
    "    print(\"VALIDATION RESULT:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(checker_result[0].content)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PIPELINE COMPLETE\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fbd3b5",
   "metadata": {},
   "source": [
    " ## 8. Run the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b991fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "RESTAURANT MENU ANALYTICS SYSTEM\n",
      "======================================================================\n",
      "\n",
      "STAGE 1: Loading CSV Data\n",
      "----------------------------------------------------------------------\n",
      "CSV data loaded successfully\n",
      "Data preview: MENU5506, Spaghetti Carbonara, pasta, 17.46, 720, True, MENU2679, Fettuccine Alfredo, pasta, 15.17, 680, True, MENU2424, Penne Arrabbiata, pasta, 15.52, 620, False, MENU1488, Lasagna Bolognese, pasta,...\n",
      "\n",
      " STAGE 2: Running Parallel Analysis\n",
      "----------------------------------------------------------------------\n",
      "MainDishAnalyzer and BeverageAnalyzer executing simultaneously...\n",
      "\n",
      "Analysis complete!\n",
      "\n",
      "RAW ANALYZER OUTPUTS:\n",
      "----------------------------------------------------------------------\n",
      "# MainDishAnalyzer: Main Dish Analysis – Descriptive Statistics\n",
      "\n",
      "Based on your provided menu data, I have extracted all MAIN DISHES (pasta, steak, chicken, fish, burgers, pizza, risotto, lamb, pork, seafood entrees). Outliers were checked and found appropriate; all included. Here are the calculated descriptive statistics as requested:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"Price Statistics Table\": {\n",
      "    \"title\": \"Main Dish Price Descriptive Statistics\",\n",
      "    \"mean_price\": 22.24,\n",
      "    \"median_price\": 18.99,\n",
      "    \"std_dev_price\": 8.42,\n",
      "    \"min_price\": 12.65,\n",
      "    \"max_price\": 42.40,\n",
      "    \"count\": 32\n",
      "  },\n",
      "  \"Nutritional Statistics Table\": {\n",
      "    \"title\": \"Main Dish Calorie Descriptive Statistics\",\n",
      "    \"mean_calories\": 669.4,\n",
      "    \"median_calories\": 680,\n",
      "    \"std_dev_calories\": 141.8\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "**Notes:**\n",
      "- 32 main dishes identified and analyzed.\n",
      "- Price and calorie statistics based exclusively on main dishes, cleaned and excluding all non-main items.\n",
      "- If you require a breakdown by dish type, let me know!\n",
      "# BeverageAnalyzer: {\n",
      "  \"Price Statistics Table\": {\n",
      "    \"title\": \"Descriptive Statistics for Beverage Prices (USD)\",\n",
      "    \"mean\": 6.88,\n",
      "    \"median\": 5.39,\n",
      "    \"standard_deviation\": 2.88,\n",
      "    \"minimum\": 1.87,\n",
      "    \"maximum\": 13.54,\n",
      "    \"count\": 32\n",
      "  },\n",
      "  \"Nutritional Statistics Table\": {\n",
      "    \"title\": \"Descriptive Statistics for Beverage Calories\",\n",
      "    \"mean\": 128.72,\n",
      "    \"median\": 120,\n",
      "    \"standard_deviation\": 103.72,\n",
      "    \"minimum\": 0,\n",
      "    \"maximum\": 520\n",
      "  }\n",
      "}\n",
      "\n",
      "**Notes:**  \n",
      "- Outliers were checked; no extreme anomalies in prices or calories based on the dataset distribution.  \n",
      "- All calculations are based on the 32 clearly identified beverages (coffee, tea, juice, soda, wine, beer, cocktails, smoothies, milkshakes, water).\n",
      "\n",
      "\n",
      "STAGE 3: Cleaning and Standardizing Outputs\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", RateLimitError(\"Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-12-01-preview have exceeded token rate limit of your current AIServices S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:88\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     87\u001b[39m         settings_dict.pop(\u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(**settings_dict)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:2583\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2582\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2583\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2584\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2585\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2586\u001b[39m         {\n\u001b[32m   2587\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2588\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2589\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2590\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2591\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2592\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2593\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2594\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2595\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2596\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2597\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2598\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2599\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2600\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2601\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2602\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2603\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   2604\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2605\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2606\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   2607\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2608\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2609\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2610\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2611\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2612\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2613\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2614\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2615\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2616\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2617\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2619\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   2620\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2621\u001b[39m         },\n\u001b[32m   2622\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2623\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2624\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2625\u001b[39m     ),\n\u001b[32m   2626\u001b[39m     options=make_request_options(\n\u001b[32m   2627\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2628\u001b[39m     ),\n\u001b[32m   2629\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2630\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2631\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2632\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/openai/_base_client.py:1794\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1791\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1792\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1793\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1794\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/openai/_base_client.py:1594\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1593\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1594\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1596\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-12-01-preview have exceeded token rate limit of your current AIServices S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m)\n\u001b[32m     46\u001b[39m clean_input = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClean the following outputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraw_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m clean_result = \u001b[38;5;28;01mawait\u001b[39;00m run_agent(agent_clean_output, clean_input)\n\u001b[32m     48\u001b[39m cleaned_output = clean_result[\u001b[32m0\u001b[39m].content\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOutput cleaned and standardized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mrun_agent\u001b[39m\u001b[34m(agent, task_input)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mExecutes an agent and collects all output messages.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m \u001b[33;03m    List of message objects from the agent\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     12\u001b[39m outputs = []\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m agent.invoke(task_input):\n\u001b[32m     14\u001b[39m     outputs.append(message)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/utils/telemetry/agent_diagnostics/decorators.py:106\u001b[39m, in \u001b[36mtrace_agent_invocation.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(invoke_func)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(\n\u001b[32m    101\u001b[39m     *args: P.args,\n\u001b[32m    102\u001b[39m     **kwargs: P.kwargs,\n\u001b[32m    103\u001b[39m ) -> AsyncIterable[AgentResponseItem[ChatMessageContent]]:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    105\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the responses\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m invoke_func(*args, **kwargs):\n\u001b[32m    107\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m response\n\u001b[32m    108\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/agents/chat_completion/chat_completion_agent.py:364\u001b[39m, in \u001b[36mChatCompletionAgent.invoke\u001b[39m\u001b[34m(self, messages, thread, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m thread.get_messages():\n\u001b[32m    362\u001b[39m     chat_history.add_message(message)\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_invoke(\n\u001b[32m    365\u001b[39m     thread,\n\u001b[32m    366\u001b[39m     chat_history,\n\u001b[32m    367\u001b[39m     on_intermediate_message,\n\u001b[32m    368\u001b[39m     arguments,\n\u001b[32m    369\u001b[39m     kernel,\n\u001b[32m    370\u001b[39m     **kwargs,\n\u001b[32m    371\u001b[39m ):\n\u001b[32m    372\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m AgentResponseItem(message=response, thread=thread)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/agents/chat_completion/chat_completion_agent.py:537\u001b[39m, in \u001b[36mChatCompletionAgent._inner_invoke\u001b[39m\u001b[34m(self, thread, history, on_intermediate_message, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    533\u001b[39m message_count_before_completion = \u001b[38;5;28mlen\u001b[39m(agent_chat_history)\n\u001b[32m    535\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invoking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m responses = \u001b[38;5;28;01mawait\u001b[39;00m chat_completion_service.get_chat_message_contents(\n\u001b[32m    538\u001b[39m     chat_history=agent_chat_history,\n\u001b[32m    539\u001b[39m     settings=settings,\n\u001b[32m    540\u001b[39m     kernel=kernel,\n\u001b[32m    541\u001b[39m     arguments=arguments,\n\u001b[32m    542\u001b[39m )\n\u001b[32m    544\u001b[39m logger.debug(\n\u001b[32m    545\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] Invoked \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(chat_completion_service).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    546\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith message count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage_count_before_completion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m )\n\u001b[32m    549\u001b[39m \u001b[38;5;66;03m# Drain newly added tool messages since last index to maintain\u001b[39;00m\n\u001b[32m    550\u001b[39m \u001b[38;5;66;03m# correct order and avoid duplicates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/connectors/ai/chat_completion_client_base.py:139\u001b[39m, in \u001b[36mChatCompletionClientBase.get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m use_span(\u001b[38;5;28mself\u001b[39m._start_auto_function_invocation_activity(kernel, settings), end_on_exit=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings.function_choice_behavior.maximum_auto_invoke_attempts):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m         completions = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_chat_message_contents(chat_history, settings)\n\u001b[32m    140\u001b[39m         \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n\u001b[32m    141\u001b[39m         \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n\u001b[32m    142\u001b[39m         function_calls = [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m completions[\u001b[32m0\u001b[39m].items \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, FunctionCallContent)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/utils/telemetry/model_diagnostics/decorators.py:112\u001b[39m, in \u001b[36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(completion_func)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(*args: Any, **kwargs: Any) -> \u001b[38;5;28mlist\u001b[39m[ChatMessageContent]:\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    111\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(*args, **kwargs)\n\u001b[32m    114\u001b[39m     completion_service: \u001b[33m\"\u001b[39m\u001b[33mChatCompletionClientBase\u001b[39m\u001b[33m\"\u001b[39m = args[\u001b[32m0\u001b[39m]\n\u001b[32m    115\u001b[39m     chat_history: ChatHistory = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[32m1\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_chat_completion_base.py:88\u001b[39m, in \u001b[36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings)\u001b[39m\n\u001b[32m     85\u001b[39m settings.messages = \u001b[38;5;28mself\u001b[39m._prepare_chat_history_for_request(chat_history)\n\u001b[32m     86\u001b[39m settings.ai_model_id = settings.ai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_id\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_request(settings)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m     90\u001b[39m response_metadata = \u001b[38;5;28mself\u001b[39m._get_metadata_from_chat_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:60\u001b[39m, in \u001b[36mOpenAIHandler._send_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.TEXT \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.CHAT:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_completion_request(settings)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.EMBEDDING:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIEmbeddingPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/finalproject/lib/python3.13/site-packages/semantic_kernel/connectors/ai/open_ai/services/open_ai_handler.py:105\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m         ex,\n\u001b[32m    103\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    106\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m         ex,\n\u001b[32m    108\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n",
      "\u001b[31mServiceResponseException\u001b[39m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", RateLimitError(\"Error code: 429 - {'error': {'code': '429', 'message': 'Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-12-01-preview have exceeded token rate limit of your current AIServices S0 pricing tier. Please retry after 60 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit. For Free Account customers, upgrade to Pay as you Go here: https://aka.ms/429TrialUpgrade.'}}\"))"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finalproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
